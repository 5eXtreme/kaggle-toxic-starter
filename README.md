# starter code: Kaggle [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge 'Kaggle competition')

Here, at [Neptune](https://neptune.ml/ 'machine learning lab') we enjoy participating in the Kaggle competitions. [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge 'Kaggle competition') is especially interesting because it touches important issue of the online harassment.

We are contributing extensible starter code that will let you run your experiment straightaway.


# How to run?
This project assumes python 3.5.
1. Clone this repo

```bash
$ git clone https://github.com/neptune-ml/kaggle-toxic-starter.git
```
2. Install [PyTorch](http://pytorch.org/)
3. Install remaining requirements
```bash
$ pip3 install -r requirements.txt
```
Note that [neptune](https://neptune.ml/ 'machine learning lab') is included in the requirements file.


# Solution visualization
![pipeline_001](https://github.com/neptune-ml/kaggle-toxic-starter/blob/master/pipelines_visualizations/pipeline_001.png 'our initial pipeline')


# Code overview
ToDo

# Contributing
You are welcome to extend this pipeline and contribute your own models or procedures. We want this starter to be developed colabboratively. Therefore, at the later stage of the competition we will invite contributors to join our team on Kaggle.

# User support
1. Kaggle [discussion](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion) is our primary way of communication.
2. You can submit an [issue](https://github.com/neptune-ml/kaggle-toxic-starter/issues)
